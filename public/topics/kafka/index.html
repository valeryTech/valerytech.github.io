<!doctype html>
<html lang="en" data-bs-theme="auto">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><link rel="preload" href="http://localhost:1313/fonts/vendor/jost/jost-v4-latin-regular.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="http://localhost:1313/fonts/vendor/jost/jost-v4-latin-500.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="http://localhost:1313/fonts/vendor/jost/jost-v4-latin-700.woff2" as="font" type="font/woff2" crossorigin>
<script 
  src="/js/color-mode.f14b3e296de1d0b69e75af684b62a4a912a2cadab04e36123407cd8388204f1d.js"
  integrity="sha256-8Us&#43;KW3h0Laeda9oS2KkqRKiytqwTjYSNAfNg4ggTx0=">
</script>


<link rel="stylesheet" href="/main.1542a5884e04a94d737f95f75653bbae5d9d951aeefab7705a9db5f7a85e58fed8b1c2f686c1303120bb66c4ac2cbfbf1317d05cde7d463eccc899dbb8088787.css" integrity="sha512-FUKliE4EqU1zf5X3VlO7rl2dlRru&#43;rdwWp2196heWP7YscL2hsEwMSC7ZsSsLL&#43;/ExfQXN59Rj7MyJnbuAiHhw==" crossorigin="anonymous">

<noscript><style>img.lazyload { display: none; }</style></noscript><base href="http://localhost:1313/topics/kafka/">

  <link rel="canonical" href="http://localhost:1313/topics/kafka/">


<title>Kafka  |  System Design</title>
<meta name="description" content="Default Description">

    
    <link rel="icon" href="/favicon.ico" sizes="32x32">
    
      <link rel="icon" href="/favicon.svg" type="image/svg+xml">
    
      <link
        rel="apple-touch-icon"
        href="/apple-touch-icon.png"
        sizes="180x180"
        type="image/png"
      >
      <link
        rel="icon"
        href="/favicon-192x192.png"
        sizes="192x192"
        type="image/png"
      >
      <link
        rel="icon"
        href="/favicon-512x512.png"
        sizes="512x512"
        type="image/png"
      >
<link rel="manifest" href="/manifest.webmanifest">

<meta property="og:url" content="http://localhost:1313/topics/kafka/">
  <meta property="og:site_name" content="System Design">
  <meta property="og:title" content="Kafka">
  <meta property="og:description" content="Default Description">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="topics">
    <meta property="article:published_time" content="2025-02-21T12:11:28+00:00">
    <meta property="article:modified_time" content="2025-02-21T12:11:28+00:00">
    <meta property="og:image" content="http://localhost:1313/cover.png">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="http://localhost:1313/cover.png">
  <meta name="twitter:title" content="Kafka">
  <meta name="twitter:description" content="Default Description">
      <meta name="twitter:site" content="@tecvalery">

    
    <script type="application/ld+json">
  {
   "@context": "https://schema.org",
   "@type": "BreadcrumbList",
   "itemListElement": [
     {
       "@type": "ListItem",
       "item": "http://localhost:1313/",
       "name": "System Design and Software Architecture 1",
       "position": 1
     },
     {
       "@type": "ListItem",
       "item": "http://localhost:1313/topics/",
       "name": "Topics",
       "position": 2
     },
     {
       "@type": "ListItem",
       "name": "Kafka",
       "position": 3
     }
   ]
 }
</script>




  
    
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-XF1V06CDS3"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-XF1V06CDS3');
        }
      </script>
    
  




</head>

  
  <body class="single section topics" data-bs-spy="scroll" data-bs-target="#toc" data-bs-root-margin="0px 0px -60%" data-bs-smooth-scroll="true" tabindex="0">
    <div class="sticky-top">
<header class="navbar navbar-expand-lg">
  <div class="container-lg">
  
    <a class="navbar-brand me-auto me-lg-3" href="/">System Design</a>

    
    
    <button type="button" id="searchToggleMobile" class="btn btn-link nav-link mx-2 d-lg-none" aria-label="Search website">
      <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
        <circle cx="10" cy="10" r="7"></circle>
        <line x1="21" y1="21" x2="15" y2="15"></line>
      </svg>
    </button>
    
    
    <button class="btn btn-link nav-link mx-2 order-3 d-lg-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvasNavMain" aria-controls="offcanvasNavMain" aria-label="Open main navigation menu">
      <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-menu" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
        <line x1="4" y1="8" x2="20" y2="8"></line>
        <line x1="4" y1="16" x2="20" y2="16"></line>
      </svg>
    </button>

    
    <div class="offcanvas offcanvas-end h-auto" tabindex="-1" id="offcanvasNavMain" aria-labelledby="offcanvasNavMainLabel">
      <div class="offcanvas-header">
        <h5 class="offcanvas-title" id="offcanvasNavMainLabel">System Design</h5>
        <button type="button" class="btn btn-link nav-link p-0 ms-auto" data-bs-dismiss="offcanvas" aria-label="Close">
          <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-x" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
            <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
            <path d="M18 6l-12 12"></path>
            <path d="M6 6l12 12"></path>
         </svg>
        </button>
      </div>
      
      <div class="offcanvas-body d-flex flex-column flex-lg-row justify-content-between">
        <ul class="navbar-nav flex-grow-1"><li class="nav-item">
                <a class="nav-link" href="http://localhost:1313/docs/guides/example-guide/">Docs</a>
              </li>
            <li class="nav-item">
                <a class="nav-link" href="http://localhost:1313/system-design/about">System Design</a>
              </li>
            <li class="nav-item">
                <a class="nav-link" href="http://localhost:1313/blog/">Blog</a>
              </li>
            </ul>

        
        
        <button type="button" id="searchToggleDesktop" class="btn btn-link nav-link p-2 d-none d-lg-block" aria-label="Search website">
          <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
            <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
            <circle cx="10" cy="10" r="7"></circle>
            <line x1="21" y1="21" x2="15" y2="15"></line>
          </svg>
        </button>
        
        
        
        <button id="buttonColorMode" class="btn btn-link mx-auto nav-link p-0 ms-lg-2 me-lg-1" type="button" aria-label="Toggle theme">
          <svg data-bs-theme-value="dark" xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-moon" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
            <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
            <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z"></path>
          </svg>
          <svg data-bs-theme-value="light" xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-sun" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
            <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
            <path d="M12 12m-4 0a4 4 0 1 0 8 0a4 4 0 1 0 -8 0m-5 0h1m8 -9v1m8 8h1m-9 8v1m-6.4 -15.4l.7 .7m12.1 -.7l-.7 .7m0 11.4l.7 .7m-12.1 -.7l-.7 .7"></path>
          </svg>
        </button>
        
        <ul id="socialMenu" class="nav mx-auto flex-row order-lg-4">
          <li class="nav-item">
              <a class="nav-link social-link" href="https://github.com/valeryTech"><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"></path><path d="M9 19c-4.3 1.4 -4.3 -2.5 -6 -3m12 5v-3.5c0 -1 .1 -1.4 -.5 -2c2.8 -.3 5.5 -1.4 5.5 -6a4.6 4.6 0 0 0 -1.3 -3.2a4.2 4.2 0 0 0 -.1 -3.2s-1.1 -.3 -3.5 1.3a12.3 12.3 0 0 0 -6.2 0c-2.4 -1.6 -3.5 -1.3 -3.5 -1.3a4.2 4.2 0 0 0 -.1 3.2a4.6 4.6 0 0 0 -1.3 3.2c0 4.6 2.7 5.7 5.5 6c-.6 .6 -.6 1.2 -.5 2v3.5"></path></svg><small class="ms-2 visually-hidden">GitHub</small></a>
            </li>
          </ul>
        
        </div>
    </div>

    
    </div>
</header>
</div>

<div class="modal" id="searchModal" tabindex="-1" aria-labelledby="searchModalLabel" aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-fullscreen-md-down">
    <div class="modal-content">
      <div class="modal-header">
        <h1 class="modal-title fs-5 visually-hidden" id="searchModalLabel">Search</h1>
        <button type="button" class="btn-close visually-hidden" data-bs-dismiss="modal" aria-label="Close"></button>
        <div class="search-input flex-grow-1 d-none">
          <form id="search-form" class="search-form" action="#" method="post" accept-charset="UTF-8" role="search">
            <label for="query" class="visually-hidden">Search</label>
            <div class="d-flex">
              <input type="search" id="query" name="query" class="search-text form-control form-control-lg" placeholder="Search" aria-label="Search" maxlength="128" autocomplete="off">
              <button type="button" class="btn btn-link text-decoration-none px-0 ms-3 d-md-none" data-bs-dismiss="modal" aria-label="Close">Cancel</button>
            </div>
          </form>
        </div>
      </div>
      <div class="modal-body">
        <p class="search-loading status message d-none mt-3 text-center">Loading search index…</p>
        <p class="search-no-recent message d-none mt-3 text-center">No recent searches</p>
        <p class="search-no-results message d-none mt-3 text-center">No results for "<strong><span class="query-no-results">Query here</span></strong>"</p>
        <div id="searchResults" class="search-results"></div>
        <template>
          <article class="search-result list-view">
            <div class="card my-3">
              <div class="card-body">
                <header>
                  <h2 class="h5 title title-submitted mb-0"><a class="stretched-link text-decoration-none text-reset" href="#">Title here</a></h2>
                  <div class="submitted d-none"><time class="created-date">Date here</time></div>
                </header>
                <div class="content">Summary here</div>
              </div>
            </div>
          </article>
        </template>
      </div>
      <div class="modal-footer">
        <ul class="list-inline me-auto d-none d-md-block">
          <li class="list-inline-item"><kbd class="me-2"><svg width="15" height="15" aria-label="Enter key" role="img"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M12 3.53088v3c0 1-1 2-2 2H4M7 11.53088l-3-3 3-3"></path></g></svg></kbd><span class="DocSearch-Label">to select</span></li>
          <li class="list-inline-item"><kbd class="me-2"><svg width="15" height="15" aria-label="Arrow down" role="img"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M7.5 3.5v8M10.5 8.5l-3 3-3-3"></path></g></svg></kbd><kbd class="me-2"><svg width="15" height="15" aria-label="Arrow up" role="img"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M7.5 11.5v-8M10.5 6.5l-3-3-3 3"></path></g></svg></kbd><span class="DocSearch-Label">to navigate</span></li>
          <li class="list-inline-item"><kbd class="me-2"><svg width="15" height="15" aria-label="Escape key" role="img"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M13.6167 8.936c-.1065.3583-.6883.962-1.4875.962-.7993 0-1.653-.9165-1.653-2.1258v-.5678c0-1.2548.7896-2.1016 1.653-2.1016.8634 0 1.3601.4778 1.4875 1.0724M9 6c-.1352-.4735-.7506-.9219-1.46-.8972-.7092.0246-1.344.57-1.344 1.2166s.4198.8812 1.3445.9805C8.465 7.3992 8.968 7.9337 9 8.5c.032.5663-.454 1.398-1.4595 1.398C6.6593 9.898 6 9 5.963 8.4851m-1.4748.5368c-.2635.5941-.8099.876-1.5443.876s-1.7073-.6248-1.7073-2.204v-.4603c0-1.0416.721-2.131 1.7073-2.131.9864 0 1.6425 1.031 1.5443 2.2492h-2.956"></path></g></svg></kbd><span class="DocSearch-Label">to close</span></li>
        </ul>
        <p class="d-md-none">Search by <a class="text-decoration-none" href="https://github.com/nextapps-de/flexsearch">FlexSearch</a></p>
      </div>
    </div>
  </div>
</div>


    <div class="wrap container-lg" role="document">
      <div class="content">
      
        
	<div class="row flex-xl-nowrap">
		
		<nav class="docs-toc d-none d-xl-block col-xl-3" aria-label="Secondary navigation">
			<div class="page-links">
  <h3>On this page</h3>
    <nav id="toc">
  <ul>
    <li><a href="#topics">Topics</a></li>
    <li><a href="#partitions">Partitions</a></li>
    <li><a href="#offsets">Offsets</a></li>
  </ul>

  <ul>
    <li><a href="#structure-of-producer">Structure of Producer</a></li>
    <li><a href="#settings">Settings</a></li>
  </ul>

  <ul>
    <li><a href="#consumer-groups">Consumer Groups</a></li>
    <li><a href="#partition-assignment">Partition Assignment</a></li>
    <li><a href="#static-group-membership">Static Group Membership</a></li>
    <li><a href="#consumer-position">Consumer Position</a></li>
    <li><a href="#partition-rebalance">Partition rebalance</a></li>
    <li><a href="#consumer-flow">Consumer Flow</a></li>
    <li><a href="#why-use-consumer-offsets">Why use Consumer Offsets?</a></li>
    <li><a href="#delivery-semantics">Delivery Semantics</a></li>
    <li><a href="#automatic-offset-committing-strategy">Automatic Offset Committing Strategy</a></li>
    <li><a href="#commit-current-offset">Commit current offset</a></li>
    <li><a href="#faults-and-errors-processing">Faults and Errors processing</a></li>
    <li><a href="#offset-management">Offset management</a></li>
    <li><a href="#consumer-advanced-topics">Consumer Advanced Topics</a></li>
  </ul>
</nav>
</div>

		</nav>
		<main class="docs-content col-lg-11 col-xl-9">
		
			<h1>Kafka</h1>
			
			<nav class="toc-mobile d-xl-none" aria-label="Quaternary navigation">
				<details>
    <summary>On this page</summary>
    <div class="page-links">
      <nav id="TableOfContents">
  <ul>
    <li><a href="#topics">Topics</a></li>
    <li><a href="#partitions">Partitions</a></li>
    <li><a href="#offsets">Offsets</a></li>
  </ul>

  <ul>
    <li><a href="#structure-of-producer">Structure of Producer</a></li>
    <li><a href="#settings">Settings</a></li>
  </ul>

  <ul>
    <li><a href="#consumer-groups">Consumer Groups</a></li>
    <li><a href="#partition-assignment">Partition Assignment</a></li>
    <li><a href="#static-group-membership">Static Group Membership</a></li>
    <li><a href="#consumer-position">Consumer Position</a></li>
    <li><a href="#partition-rebalance">Partition rebalance</a></li>
    <li><a href="#consumer-flow">Consumer Flow</a></li>
    <li><a href="#why-use-consumer-offsets">Why use Consumer Offsets?</a></li>
    <li><a href="#delivery-semantics">Delivery Semantics</a></li>
    <li><a href="#automatic-offset-committing-strategy">Automatic Offset Committing Strategy</a></li>
    <li><a href="#commit-current-offset">Commit current offset</a></li>
    <li><a href="#faults-and-errors-processing">Faults and Errors processing</a></li>
    <li><a href="#offset-management">Offset management</a></li>
    <li><a href="#consumer-advanced-topics">Consumer Advanced Topics</a></li>
  </ul>
</nav>
    </div>
  </details>

			</nav>
			<p>Kafka is a distributed system consisting of <strong>servers</strong> and <strong>clients</strong> that communicate via a high-performance <a href="https://kafka.apache.org/protocol.html">TCP network protocol</a>.</p>
<p>Apache Kafka itself has specific characteristics, as of: distributed, fault tolerant, has horizontal scalability, resilient architecture.</p>
<p>Var:</p>
<ul>
<li>Serialization/deserealization type must not change during a topic lifecycle.</li>
<li>You can use Kafka Consumers Replica Fetching (reading from ISR not a Leader) to improve latency and also decrease network costs if using a cloud.</li>
<li>In Kafka, there is no support for wildcard topic selection on server side. The topic name has to be an exact match.</li>
</ul>
<h1 id="questions">Questions</h1>
<p>How Apache Kafka is scaling?
What the main parts of AK?</p>
<p>to investigate and/or create:
definition of integration
definition of Kafka
various scenarios to play
play scenario when producer <code>acks=all</code> and none of the brokers are available
producer flow
consumer flow
producer modes and acks
how to monitor/profile producers and consumers (average batch size, etc.)
how to quickly find and process specific type of messages?
errors:</p>
<ul>
<li>when a producer is crashed</li>
<li>when a consumer is crashed
how producer works internally
how consumer works internally
tuning Kafka</li>
</ul>
<p>build and replay scenarios</p>
<p>questions from internet:
https://www.projectpro.io/article/kafka-interview-questions-and-answers/438#mcetoc_1g6amq60m3qp</p>
<h1 id="use-cases">Use cases</h1>
<p>check and describe videos from conduktor&rsquo;s course and definitife guide</p>
<h1 id="main-concepts">Main Concepts</h1>
<p>An <strong>event</strong> records the fact that &ldquo;something happened&rdquo; in the world or in your business. It is also called record or message in the documentation. When you read or write data to Kafka, you do this in the form of events. Conceptually, an event has a key, value, timestamp, and optional metadata headers. (1)</p>
<p><strong>Producers</strong> are those client applications that publish (write) events to Kafka, and <strong>consumers</strong> are those that subscribe to (read and process) these events. In Kafka, producers and consumers are fully decoupled and agnostic of each other, which is a key design element to achieve the high scalability that Kafka is known for. For example, producers never need to wait for consumers.</p>
<p>The documentation of Kafka introduces a chapter with API description aslo. So this is a important point to the creators of Kafka.</p>
<h2 id="topics">Topics<a href="#topics" class="anchor" aria-hidden="true">#</a> </h2>
<p>Definition 1. Events are organized and durably stored in <strong>topics</strong>. Very simplified, a topic is similar to a folder in a filesystem, and the events are the files in that folder. An example topic name could be &ldquo;payments&rdquo;. Topics in Kafka are always multi-producer and multi-subscriber: a topic can have zero, one, or many producers that write events to it, as well as zero, one, or many consumers that subscribe to these events. Events in a topic can be read as often as needed—unlike traditional messaging systems, events are not deleted after consumption.
Definition 2. Kafka topics are the categories used to organize messages.
Definition 3. According to another definitions topic is a particular stream of data.</p>
<p>You cannot query topics.
Kafka topics are <strong>immutable</strong>: once data is written to a partition, it cannot be changed</p>
<h2 id="partitions">Partitions<a href="#partitions" class="anchor" aria-hidden="true">#</a> </h2>
<p><strong>What are Kafka Partitions?</strong>
Topics are broken down into a number of partitions. A single topic may have more than one partition, it is common to see topics with 100 partitions.</p>
<h2 id="offsets">Offsets<a href="#offsets" class="anchor" aria-hidden="true">#</a> </h2>
<p>The offset is an integer value that Kafka adds to each message as it is written into a partition. Each message in a given partition has a unique offset.</p>
<p><em>Kafka Offset Ordering</em>
Offset only has a meaning for a specific partition.
If a topic has more than one partition, Kafka guarantees the order of messages within a partition, but there is no ordering of messages across partitions.</p>
<h1 id="producers">Producers</h1>
<p>Applications that send data into topics are known as Kafka producers.</p>
<p>There are many reasons an application might need to write messages to Kafka: recording user activities for auditing or analysis, recording metrics, storing log messages, recording information from smart appliances, communicating asynchronously with other applications, buffering information before writing to a database, and much more.
Those diverse use cases also imply diverse requirements: is every message critical, or can we tolerate loss of messages? Are we OK with accidentally duplicating messages? Are there any strict latency or throughput requirements we need to support?</p>
<p>A Kafka producer sends messages to a topic, and messages are distributed to partitions according to a mechanism such as key hashing. Producers know to which partition to write to (and which Kafka broker has it).</p>
<p>There are three primary methods of sending messages:</p>
<p><strong>Fire-and-forget</strong>
We send a message to the server and don&rsquo;t really care if it arrives successfully or not. Most of the time, it will arrive successfully, since Kafka is highly available and the producer will retry sending messages automatically. However, in case of nonretriable errors or timeout, messages will get lost and the application will not get any information or exceptions about this.</p>
<p><strong>Synchronous send</strong>
Technically, Kafka producer is always asynchronous—we send a message and the send() method returns a Future object. However, we use can use get() to wait on the Future and see if the send() was successful or not before sending the next record.
If you send messages synchronously, the sending thread will spend this time waiting and doing nothing else, not even sending additional messages. This leads to very poor performance, and as a result, synchronous sends are usually not used in production applications (but are very common in code examples).</p>
<p><strong>Asynchronous send</strong>
We call the send() method with a callback function. A callback method the user can implement to provide asynchronous handling of request completion. This method will be called when the record sent to the server has been acknowledged.</p>
<p><strong>Errors.</strong></p>
<p>KafkaProducer has two types of errors. Retriable errors are those that can be resolved by sending the message again. For example, a connection error can be resolved because the connection may get reestablished. A &ldquo;not leader for partition&rdquo; error can be resolved when a new leader is elected for the partition and the client metadata is refreshed. KafkaProducer can be configured to retry those errors automatically, so the application code will get retriable exceptions only when the number of retries was exhausted and the error was not resolved. Some errors will not be resolved by retrying — for example, &ldquo;Message size too large.&rdquo; In those cases, KafkaProducer will not
attempt a retry and will return the exception immediately.</p>
<p>Also there are some alogrithms created by conduktor in the udemy course.
Producer reprocessing images?</p>
<p><strong>Idempotent producer</strong></p>
<p><strong>Message Keys</strong>.</p>
<p>Each event message contains an optional key and a value. Keys serve two goals: they are additional information that gets stored with the message, and they are typically also used to decide which one of the topic partitions the message will be written to (keys also play an important role in compacted topics). All messages with the same key will go to the same partition. This means that if a process is reading only a subset of the partitions in a topic, all the records for a single key will be read by the same process.</p>
<p><strong>Key hashing.</strong> A Kafka partitiones which resides in <code>Producer</code> is a code that takes a record and determines to which partition to sent it into. Adding partitions to a topic completely alters the hashing formula and thus keys to partitions mapping.</p>
<p><strong>Headers</strong>. There can be a list of optional Kafka message headers in the form of key-value pairs. It is common to add headers to specify metadata about the message, especially for tracing.</p>
<p><strong>Partition + Offset</strong>. Once a message is sent into a Kafka topic, it receives a partition number and an offset id. The combination of topic+partition+offset uniquely identifies the message</p>
<h2 id="structure-of-producer">Structure of Producer<a href="#structure-of-producer" class="anchor" aria-hidden="true">#</a> </h2>
<p>Producer has a batch per partitions for messages to send. The sizes of these batches are controllable.</p>
<h2 id="settings">Settings<a href="#settings" class="anchor" aria-hidden="true">#</a> </h2>
<p><strong>Message Durability.</strong></p>
<p>For data durability, the <code>KafkaProducer</code> has the configuration setting <code>acks</code>. The <code>acks</code> configuration specifies how many acknowledgments the producer receives to consider a record delivered to the broker. The options to choose from are:</p>
<ul>
<li><code>none</code>: The producer considers the records successfully delivered once it sends the records to the broker. This is basically &ldquo;fire and forget.&rdquo;</li>
<li><code>one</code>: The producer waits for the lead broker to acknowledge that it has written the record to its log.</li>
<li><code>all</code>: The producer waits for an acknowledgment from the lead broker and from the following brokers that they have successfully written the record to their logs.</li>
</ul>
<p><strong>Message Ordering.</strong></p>
<p><strong>Queuing Limits</strong>: Use <code>buffer.memory</code> to limit the total memory that is available to the Java client for collecting unsent messages. When this limit is hit, the producer will block on additional sends for as long as <code>max.block.ms</code> before raising an exception. Additionally, to avoid keeping records queued indefinitely, you can set a timeout using <code>request.timeout.ms</code>.</p>
<p><strong>Batching and compression.</strong>
Two settings to influence the batching mechanism:
<code>linger.ms</code> - how long to wait until we send a batch (for example <code>5ms</code>)
<code>batch.size</code> -  maximum number of bytes that will be included into a batch (for example 32KB or 64KB)</p>
<p>For a message to be successfully written into a Kafka topic, a producer must specify a level of acknowledgment (acks).</p>
<p>https://strimzi.io/blog/2020/10/15/producer-tuning/</p>
<ul>
<li>also you should use producer compression</li>
</ul>
<h1 id="consumers">Consumers</h1>
<p>Applications that need to read data from Kafka use a KafkaConsumer to subscribe to Kafka topics and receive messages from these topics. Reading data from Kafka is a bit different than reading data from other messaging systems, and there are a few unique concepts and ideas involved. It can be difficult to understand how to use the Consumer API without understanding these concepts first.</p>
<p>Kafka consumers are also known to implement a &ldquo;pull model&rdquo;. This means that Kafka consumers must request data from Kafka brokers in order to get it (instead of having Kafka brokers continuously push data to consumers). This implementation was made so that consumers can control the speed at which the topics are being consumed.</p>
<p>The consumer API is centered around the <code>poll()</code> method, which is used to retrieve records from the brokers. The <code>subscribe()</code> method controls which topics will be fetched in poll. Typically, consumer usage involves an initial call to <code>subscribe()</code> to setup the topics of interest and then a loop which calls <code>poll()</code> until the application is shutdown.</p>
<p>The poll loop does a lot more than just get data. The first time you call poll() with a new consumer, it is responsible for finding the GroupCoordinator, joining the consumer group, and receiving a partition assignment. If a rebalance is triggered, it will be handled inside the poll loop as well, including related callbacks. This means that almost everything that can go wrong with a consumer or in the callbacks used in its listeners is likely to show up as an exception thrown by poll().</p>
<p>Keep in mind that if poll() is not invoked for longer than max.poll.interval.ms, the consumer will be considered dead and evicted from the consumer group, so avoid doing anything that can block for unpredictable intervals inside the poll loop.</p>
<h2 id="consumer-groups">Consumer Groups<a href="#consumer-groups" class="anchor" aria-hidden="true">#</a> </h2>
<p>We have seen that consumers can consume data from Kafka topics partitions individually, but for horizontal scalability purposes it is recommended to consume Kafka topics as a group. Consumers that are part of the same application and therefore performing the same &ldquo;logical job&rdquo; can be grouped together as a Kafka consumer group.</p>
<p>The benefit of leveraging a Kafka consumer group is that the consumers within the group will coordinate to split the work of reading from different partitions.</p>
<h2 id="partition-assignment">Partition Assignment<a href="#partition-assignment" class="anchor" aria-hidden="true">#</a> </h2>
<p>Kafka Clients allows you to implement your own partition assignment strategies for consumers. This can be very useful to adapt to specific deployment scenarios, such as the failover example we used in this post. In addition, the ability to transmit user data to the consumer leader during rebalancing can be leveraged to implement more complex and stateful algorithms, such as one developed for Kafka Stream (https://medium.com/streamthoughts/understanding-kafka-partition-assignment-strategies-and-how-to-write-your-own-custom-assignor-ebeda1fc06f3)</p>
<h2 id="static-group-membership">Static Group Membership<a href="#static-group-membership" class="anchor" aria-hidden="true">#</a> </h2>
<p>By default, the identity of a consumer as a member of its consumer group is transient. When consumers leave a consumer group, the partitions that were assigned to the consumer are revoked, and when it rejoins, it is assigned a new member ID and a new set of partitions through the rebalance protocol.
All this is true unless you configure a consumer with a unique group.instance.id, which makes the consumer a static member of the group. When a consumer first joins a consumer group as a static member of the group, it is assigned a set of partitions according to the partition assignment strategy the group is using, as normal. However, when this consumer shuts down, it does not automatically leave the group—it remains a member of the group until its session times out. When the consumer rejoins the group, it is recognized with its static identity and is reassigned the same partitions it previously held without triggering a rebalance. The group coordinator that caches the assignment for each member of the group does not need to trigger a rebalance but can just send the cache assignment to the rejoining static member.</p>
<p>Terms:
Coordinator; heartbeats; rebalance process;</p>
<h2 id="consumer-position">Consumer Position<a href="#consumer-position" class="anchor" aria-hidden="true">#</a> </h2>
<p>Keeping track of <em>what</em> has been consumed is, surprisingly, one of the key performance points of a messaging system.</p>
<p>Kafka brokers use an internal topic named <code>__consumer_offsets</code> that keeps track of what messages a given <strong>consumer group</strong> last successfully processed.</p>
<p>Kafka handles this differently than other messaging systems (from documentation). Our topic is divided into a set of totally ordered partitions, each of which is consumed by exactly one consumer within each subscribing consumer group at any given time. This means that the position of a consumer in each partition is just a single integer, the offset of the next message to consume. This makes the state about what has been consumed very small, just one number for each partition. This state can be periodically checkpointed. This makes the equivalent of message acknowledgements very cheap.</p>
<p>There is a side benefit of this decision. A consumer can deliberately <em>rewind</em> back to an old offset and re-consume data. This violates the common contract of a queue, but turns out to be an essential feature for many consumers. For example, if the consumer code has a bug and is discovered after some messages are consumed, the consumer can re-consume those messages once the bug is fixed.</p>
<h2 id="partition-rebalance">Partition rebalance<a href="#partition-rebalance" class="anchor" aria-hidden="true">#</a> </h2>
<p>As we saw in the previous section, consumers in a consumer group share ownership of the partitions in the topics they subscribe to. When we add a new consumer to the group, it starts consuming messages from partitions previously consumed by another consumer. The same thing happens when a consumer shuts down or crashes; it leaves the group, and the partitions it used to consume will be consumed by one of the remaining consumers. Reassignment of partitions to consumers also happens when the topics the consumer group is consuming are modified (e.g., if an administrator adds new partitions).</p>
<p>Moving partition ownership from one consumer to another is called a rebalance. Rebalances are important because they provide the consumer group with high availability and scalability (allowing us to easily and safely add and remove consumers), but in the normal course of events they can be fairly undesirable.</p>
<p>There are two types of rebalances, depending on the partition assignment strategy that the consumer group uses:</p>
<p>Strategies:</p>
<ul>
<li>Eager Rebalance. By default, consumers perform eager rebalancing, which means that all consumers stop consuming from Apache Kafka and give up the membership of their partitions. During this period of time, the entire consumer group stops processing, this is also called a <em>&ldquo;stop the world&rdquo;</em> event. They will rejoin the consumer group and get a new partition assignment, but <em>don&rsquo;t necessarily &ldquo;get back&rdquo;</em> the partitions that were previously assigned to them.</li>
<li>Cooperative rebalances. These (also called incremental rebalances) typically involve reassigning only a small subset of the partitions from one consumer to another, and allowing consumers to continue processing records from all the partitions that are not reassigned. This is achieved by rebalancing in two or more phases.</li>
</ul>
<p>https://medium.com/streamthoughts/apache-kafka-rebalance-protocol-or-the-magic-behind-your-streams-applications-e94baf68e4f2</p>
<p><strong>Rebalance Listeners</strong></p>
<p>As we mentioned in the previous section about committing offsets, a consumer will want to do some cleanup work before exiting and also before partition rebalancing.</p>
<p>If you know your consumer is about to lose ownership of a partition, you will want to commit offsets of the last event you&rsquo;ve processed. Perhaps you also need to close file handles, database connections, and such.</p>
<p>The Consumer API allows you to run your own code when partitions are added or removed from the consumer. You do this by passing a ConsumerRebalanceListener when calling the subscribe() method we discussed previously.</p>
<h2 id="consumer-flow">Consumer Flow<a href="#consumer-flow" class="anchor" aria-hidden="true">#</a> </h2>
<h2 id="why-use-consumer-offsets">Why use Consumer Offsets?<a href="#why-use-consumer-offsets" class="anchor" aria-hidden="true">#</a> </h2>
<p>Offsets are critical for many applications. If a Kafka client crashes, a rebalance occurs and the latest committed offset help the remaining Kafka consumers know where to restart reading and processing messages.</p>
<p>In case a new consumer is added to a group, another consumer group rebalance happens and consumer offsets are yet again leveraged to notify consumers where to start reading data from.</p>
<p>Therefore consumer offsets must be committed regularly.</p>
<h2 id="delivery-semantics">Delivery Semantics<a href="#delivery-semantics" class="anchor" aria-hidden="true">#</a> </h2>
<h2 id="automatic-offset-committing-strategy">Automatic Offset Committing Strategy<a href="#automatic-offset-committing-strategy" class="anchor" aria-hidden="true">#</a> </h2>
<p>By default, the property <code>enable.auto.commit=true</code> and therefore offsets are committed automatically with a frequency controlled by the config <code>auto.commit.interval.ms</code>.</p>
<p>The process of committing the offsets happens when: the <code>.poll()</code> function is called AND the time between two calls to <code>.poll()</code> is greater than the setting <code>auto.commit.interval.ms</code> (5 seconds by default).</p>
<h2 id="commit-current-offset">Commit current offset<a href="#commit-current-offset" class="anchor" aria-hidden="true">#</a> </h2>
<p>Most developers exercise more control over the time at which offsets are committed—both to eliminate the possibility of missing messages and to reduce the number of messages duplicated during rebalancing. The Consumer API has the option of committing the current offset at a point that makes sense to the application developer rather than based on a timer.</p>
<p>How to commit
This means that to be in an &ldquo;at-least-once&rdquo; processing use case (the most desirable one), you need to ensure all the messages in your consumer code are successfully processed before performing another <code>.poll()</code> call (which is the case in the sample code defined above). If this is not the case, then offsets could be committed before the messages are actually processed, therefore resulting in an &ldquo;at-most once&rdquo; processing pattern, possibly resulting in message skipping (which is undesirable).</p>
<p>In that (rare) case, you must disable <code>enable.auto.commit</code>, and most likely most processing to a separate thread, and then from time to time call <code>.commitSync()</code> or <code>.commitAsync()</code>with the correct offsets manually.</p>
<p>(https://www.conduktor.io/kafka/delivery-semantics-for-kafka-consumers#Automatic-Offset-Committing-Strategy-4)</p>
<h2 id="faults-and-errors-processing">Faults and Errors processing<a href="#faults-and-errors-processing" class="anchor" aria-hidden="true">#</a> </h2>
<p>In a distributed system, consumers might encounter all sorts of issues including network issues, crashes, restarts etc.</p>
<h2 id="offset-management">Offset management<a href="#offset-management" class="anchor" aria-hidden="true">#</a> </h2>
<p>https://docs.confluent.io/3.0.0/clients/consumer.html#detailed-examples</p>
<h2 id="consumer-advanced-topics">Consumer Advanced Topics<a href="#consumer-advanced-topics" class="anchor" aria-hidden="true">#</a> </h2>
<p>https://www.conduktor.io/kafka/advanced-kafka-consumer-with-java</p>
<h1 id="exactly-one-semantics">Exactly one semantics</h1>
<p>https://www.confluent.io/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/
and add some from definitive guide</p>
<h1 id="partitioning">Partitioning</h1>
<p><strong>Keys partitioning</strong>
When the default partitioner is used, the mapping of keys to partitions is consistent only as long as the number of partitions in a topic does not change. So as long as the number of partitions is constant, you can be sure that, for example, records regarding user 045189 will always get written to partition 34. This allows all kinds of optimization when reading data from partitions. However, the moment you add new partitions to the topic, this is no longer guaranteed—the old records will stay in partition 34 while new records may get written to a different partition. When partitioning keys is important, the easiest solution is to create topics with sufficient partitions and never add partitions.</p>
<p>see also <a href="kafka.md#consumer-rebalancing">Consumer rebalancing</a></p>
<p><strong>When <code>key is null</code></strong></p>
<p>In case the key (<code>key=null</code>) is not specified by the producer, messages are distributed evenly across partitions in a topic. This means messages are sent in a round-robin fashion. But in the last versions of Kafka Stricky Partitioner is a DefaultPartitioner which is used when there is no key is noticed in a record. It will fill a batch of messages sent to a single partition before switching to the next partition. This allows sending the same number of messages to Kafka in fewer requests, leading to lower latency and reduced CPU utilization on the broker.</p>
<p><strong>When <code>key!=null</code></strong></p>
<p>When choosing a partition strategy, its important to plan for resource bottlenecks and storage efficiency. In addition to the default partitioner, Apache Kafka clients also provide RoundRobin Partitioner and UniformStickyPartitioner. These provide random partition assignment and sticky random partition assignment even when messages have keys.</p>
<p><strong>Custom partitioning strategy</strong>
However, Kafka does not limit you to just hash partitions, and sometimes there are good reasons to partition data differently.</p>
<p>sources
https://www.learningjournal.guru/courses/kafka/kafka-foundation-training/custom-partitioner/</p>
<h1 id="reprocessing">Reprocessing</h1>
<p>DLQs can keep service delays from blocking the processing of your messages. For example, instead of using a unique topic for each customer to which you need to send data (potentially millions of topics),  you may prefer to use a shared topic, or a series of shared topics that contain all of your customers. But if you are sending to multiple customers from a shared topic and one customer&rsquo;s REST API is down—instead of delaying the process entirely—you can have that customer&rsquo;s events divert into a dead letter queue. You can then process them later from that queue.</p>
<p>Dead letter &amp; reprocessing:
https://www.confluent.io/blog/kafka-connect-deep-dive-error-handling-dead-letter-queues/
https://eng.uber.com/reliable-reprocessing/</p>
<p>en: Utilizing these properties, the Uber Insurance Engineering team extended Kafka&rsquo;s role in our existing event-driven architecture by using non-blocking request reprocessing and dead letter queues (DLQ) to achieve decoupled, observable error-handling without disrupting real-time traffic.</p>
<p>A DLQ should allow listing for viewing the contents of the queue, purging for clearing those contents, and merging for reprocessing the dead-lettered messages, allowing comprehensive resolution for all failures affected by a shared issue. At Uber, we needed a retry strategy that would reliably and scalably afford us these capabilities .</p>
<h1 id="compactification">Compactification</h1>
<h1 id="tuning-apache-kafka">Tuning Apache Kafka</h1>
<p>Optimum performance involves the consideration of two key measures: latency and throughput. Latency refers to the time taken to process one event. Hence a lower latency is required for better performance. Throughput denotes the number of events that can be processed in a specific amount of time, and hence, the goal is to always have a higher throughput. Many systems tend to optimize one and end up compromising the other, but Kafka attains a perfect balance of the two. </p>
<p><strong>Tuning Apache Kafka for optimal performance involves:</strong></p>
<ul>
<li>Tuning Kafka Producer: Data that the producers publish to the brokers is stored in a batch and sent only when the batch is ready. To tune the producers, two parameters are taken into consideration -
<ul>
<li>Batch Size: The batch size has to be decided based on the nature of the volume of messages sent by the producer. Producers which send messages frequently will work better with larger batch sizes so that throughput can be maximized without compromising heavily on the latency. In cases where the producers do not send messages frequently, smaller batch size is preferred. In such cases, if the batch size is very large, it may never get full or take a long time to fill up. This will increase the latency and hence, compromise performance.</li>
<li>Linger Time: The linger time is added to create a delay to allow more records to be filled up in the batch so that larger batches can be sent. A longer linger time allows more messages to be sent in one batch but can result in compromising latency. On the other hand, a reduced linger time results in fewer messages getting sent faster, and as a result, there is lower latency but reduced throughput too.</li>
</ul>
</li>
<li>Tuning Kafka Brokers: Every partition has a leader associated with it and zero or more followers for the leader. While the Kafka cluster is running, due to failures in some of the brokers or due to reallocation of partitions, an imbalance may occur among the brokers in the cluster. Some brokers might be overworked compared to others. In such cases, it is important to monitor the brokers and ensure that the workload is balanced across the various brokers present in the cluster.</li>
<li>Tuning Kafka Consumers: While tuning consumers, it is important to keep in mind that a consumer can read many partitions, but one consumer can only read one partition. A good practice to follow is to keep the number of consumers equal to or lower than the partition count. If the customers are lower than the partition count, the number of partitions can be an exact multiple of the number of consumers. More consumers than partitions will result in some consumers remaining idle.</li>
</ul>
<h1 id="partition-count">Partition Count</h1>
<p><strong>How to Choose the Number of Partitions</strong></p>
<p>https://www.confluent.io/blog/how-choose-number-topics-partitions-kafka-cluster/
https://www.conduktor.io/kafka/kafka-topics-choosing-the-replication-factor-and-partitions-count</p>
<p>The first thing to understand is that a topic partition is the unit of parallelism in Kafka. On both the producer and the broker side, writes to different partitions can be done fully in parallel. So expensive operations such as compression can utilize more hardware resources. On the consumer side, Kafka always gives a single partition&rsquo;s data to one consumer thread. Thus, the degree of parallelism in the consumer (within a consumer group) is bounded by the number of partitions being consumed. Therefore, in general, the more partitions there are in a Kafka cluster, the higher the throughput one can achieve.</p>
<p>A rough formula for picking the number of partitions is based on throughput. You measure the throughout that you can achieve on a single partition for production (call it <em>p</em>) and consumption (call it <em>c</em>). Let&rsquo;s say your target throughput is <em>t</em>. Then you need to have at least <em>max(t/p, t/c)</em> partitions. The per-partition throughput that one can achieve on the producer depends on configurations such as the batching size, compression codec, type of acknowledgement, replication factor, etc. However, in general, one can produce at 10s of MB/sec on just a single partition as shown in this <a href="https://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines">benchmark</a>. The consumer throughput is often application dependent since it corresponds to how fast the consumer logic can process each message. So, you really need to measure it.</p>
<p>Although it&rsquo;s possible to increase the number of partitions over time, one has to be careful if messages are produced with keys. When publishing a keyed message, Kafka deterministically maps the message to a partition based on the hash of the key. This provides a guarantee that messages with the same key are always routed to the same partition. This guarantee can be important for certain applications since messages within a partition are always delivered in order to the consumer. If the number of partitions changes, such a guarantee may no longer hold. To avoid this situation, a common practice is to over-partition a bit. Basically, you determine the number of partitions based on a future target throughput, say for one or two years later. Initially, you can just have a small Kafka cluster based on your current throughput. Over time, you can add more brokers to the cluster and proportionally move a subset of the existing partitions to the new brokers (which can be done online). This way, you can keep up with the throughput growth without breaking the semantics in the application when keys are used.</p>
<p>There are several factors to consider when choosing the number of partitions:</p>
<ul>
<li>What is the throughput you expect to achieve for the topic? For example, do you expect to write 100 KBps or 1 GBps?</li>
<li>What is the maximum throughput you expect to achieve when consuming from a single partition? A partition will always be consumed completely by a single consumer (even when not using consumer groups, the consumer must read all messages in the partition). If you know that your slower consumer writes the data to a database and this database never handles more than 50 MBps from each thread writing to it, then you know you are limited to 50 MBps throughput when consuming from a partition.</li>
<li>You can go through the same exercise to estimate the maximum throughput per  producer for a single partition, but since producers are typically much faster than If you are sending messages to partitions based on keys, adding partitions later can be very challenging, so calculate throughput based on your expected future usage, not the current usage.</li>
<li>Consider the number of partitions you will place on each broker and available diskspace and network bandwidth per broker.</li>
<li>Avoid overestimating, as each partition uses memory and other resources on the broker and will increase the time for metadata updates and leadership transfers.</li>
<li>Will you be mirroring data? You may need to consider the throughput of your mirroring configuration as well. Large partitions can become a bottleneck in many mirroring configurations.</li>
<li>If you are using cloud services, do you have IOPS (input/output operations per second) limitations on your VMs or disks? There may be hard caps on the number of IOPS allowed depending on your cloud service and VM configuration that will cause you to hit quotas. Having too many partitions can have the side effect of increasing the amount of IOPS due to the parallelism involved.consumers, it is usually safe to skip this.</li>
</ul>
<h1 id="apis">APIs</h1>
<p>Kafka &amp; ecosystem had introduced over time some new API that are higher level that solves specific sets of problems.
<strong>Kafka Connect.</strong> Connect Cluster (workers).</p>
<h1 id="use-the-power-of-record-headers">Use the power of record headers</h1>
<h1 id="kafka-streams">Kafka Streams</h1>
<p>it&rsquo;s an easy data processing and tranformation library within Kafka.</p>
<h1 id="sources">Sources</h1>
<p>intro
https://kafka.apache.org/intro
https://www.conduktor.io/kafka/
https://www.confluent.io/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/
https://www.confluent.io/blog/5-things-every-kafka-developer-should-know/
https://developer.confluent.io/podcast/if-streaming-is-the-answer-why-are-we-still-doing-batch/
https://www.confluent.io/blog/transactions-apache-kafka/</p>
<p>conferences
Kafka Summit
https://www.confluent.io/events/kafka-summit-london-2022/</p>
<p>use cases
https://www.confluent.io/blog/area/technology/?categories=use-cases</p>
<p>docs
https://kafka.apache.org/documentation.html#theproducer
https://kafka.apache.org/30/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html</p>
<p>courses
https://developer.confluent.io/learn-kafka/ #courses/kafka
https://developer.confluent.io/learn-kafka/apache-kafka/events/ #courses/kafka</p>
<p>Flink vs Kafka https://www.youtube.com/watch?v=Wqko7MunKZs</p>
<h1 id="questions-interview">Questions (interview)</h1>
<p>Explain some of the differences between the old consumer (in 0.8) and the new consumer (introduced in 0.9)?</p>
<p>What are all the major APIs in Kafka and when would you use one (like Kafka Connect) versus another (like Kafka Streams)?</p>
<p>What is the role of zookeeper in a Kafka cluster?</p>
<p>Explain what is a commit log, a topic, a partition, a segment, a consumer group, an offset?</p>
<p>What are the major extensibility points?</p>
<p>What is the difference between compacted topics and normal topics?</p>
<p>How is data ever deleted from Kafka?</p>
<p>What&rsquo;s is a leader?</p>
<p>What does it mean to have a replication factor of 3?</p>
<p>How does Kafka behave like a PubSub topic and also like a message queue?</p>
<p>What does the poll() method do in a consumer application?</p>
<p>What does serdes mean?</p>
<p>Explain the format of a Kafka message?</p>

			<div class="page-footer-meta d-flex flex-column flex-md-row justify-content-between">
				</div>
			<div class="page-nav d-flex flex-column flex-sm-row">
	
	<div class="card w-100">
			<div class="card-body d-flex">
				<div class="d-flex flex-column justify-content-center">
					<svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-arrow-left" width="20" height="20" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
						<path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
						<path d="M5 12l14 0"></path>
						<path d="M5 12l6 6"></path>
						<path d="M5 12l6 -6"></path>
				 	</svg>
				</div>
				<div class="d-flex flex-column">
					<div class="text-body-secondary">Prev</div>
					<a href="/topics/gamedesign/" class="stretched-link text-reset text-decoration-none">Gamedesign</a>
				</div>
			</div>
		</div>
	<div class="m-2"></div>
	<div class="card text-end w-100">
			<div class="card-body d-flex justify-content-end">
				<div class="d-flex flex-column">
					<div class="text-body-secondary">Next</div>
					<a href="/topics/kubernetes/" class="stretched-link text-reset text-decoration-none">Kubernetes</a>
				</div>
				<div class="d-flex flex-column justify-content-center">
					<svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-arrow-right" width="20" height="20" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
						<path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
						<path d="M5 12l14 0"></path>
						<path d="M13 18l6 -6"></path>
						<path d="M13 6l6 6"></path>
					</svg>
				</div>
			</div>
		</div>
	</div>

			
		</main>
		
	</div>

      
      </div>
    </div>
    
    
    <footer class="footer text-muted">
  <div class="container-lg">
    <div class="row">
      <div class="col-lg-8 text-center text-lg-start">
        <ul class="list-inline">
          <li class="list-inline-item"><a class="text-muted" href="/privacy/">Privacy Policy</a></li>
        </ul>
      </div>
      <div class="col-lg-8 text-center text-lg-end">
        <ul class="list-inline">
          <li class="list-inline-item">Brought to you by Valery</li>
        </ul>
      </div>
    </div>
  </div>
</footer>

    

<script async
  src="/js/app.342099c10d1a06642e2779fba06362135a7d6a6cad5b489601040270bae5f10e.js"
  integrity="sha256-NCCZwQ0aBmQuJ3n7oGNiE1p9amytW0iWAQQCcLrl8Q4=">
</script>





<script async
  src="/js/flexsearch.be33aab3067e96554f261851c25a593228b91154cd28ff5c7f8d52b2e7f306d2.js"
  integrity="sha256-vjOqswZ&#43;llVPJhhRwlpZMii5EVTNKP9cf41SsufzBtI=">
</script>
<script async
  src="/js/search-modal.97d606e77f08deeb37876860d99c8f6813ef29263e73b6435c252de6be98d55e.js"
  integrity="sha256-l9YG538I3us3h2hg2ZyPaBPvKSY&#43;c7ZDXCUt5r6Y1V4=">
</script>

    
  </body>
</html>